<style lang="less">
  .emoji-voice-wrap{
    position: relative;
    font-size:28rpx;
    // margin: 30rpx 30rpx 0;
    opacity: 0;
    height: 0;
    &.voice{
      background-color: #292E42;
      .speech-wrap{
        padding: 0 30rpx;
        .speech_text{
          font-family: PingFang-SC-Medium;
          font-size: 34rpx;
          color: #FFFFFF;
        }
        .voice-recording{
          display: block;
          margin: 0 auto;
          height: 20rpx;
          width: 116rpx;
        }
      }
      .wave1, .wave2{
        border-radius: 50%;
        position: absolute;
        left: 50%;
        background: #BFA87C;
        display: none;
      }
      .wave1 {
        width: 228rpx;
        height: 228rpx;
        margin-left: -114rpx;
        opacity: 0.1;
        bottom: 29rpx;
      }
      .wave2{
        opacity: 0.2;
        width: 156rpx;
        height: 156rpx;
        margin-left: -78rpx;
        bottom: 65rpx;
      }
      .recording{
        display: inline-block;
        -webkit-animation: voice-wave 0.8s ease-out infinite;
        animation: voice-wave 0.8s ease-out infinite;
      }
      .voice-btn{
        position: absolute;
        left: 50%;
        margin-left: -63rpx;
        width: 126rpx;
        height: 126rpx;
        bottom: 80rpx;
        background-color: #BFA87C;
        text-align: center;
        border-radius: 50%;
        border: none;
        &::after{
          display: none;
        }
        .voice-icon{
          display: inline-block;
          margin-top: 32rpx;
          width: 62rpx;
          border: none;
          height: 62rpx;
        }
      }
    }
    .emoji-list{
      margin: 15rpx 15rpx 0;
    }
    & .text{
      text-align: center;
      //flex: 0 0 25%;
      display: inline-block;
      padding-left: 16rpx;
      margin-bottom: 20rpx;
      background-color: #fff;
      background-clip: content-box;
      box-sizing: border-box;
      height: 70rpx;
      line-height: 70rpx;
      border-radius: 8rpx;
      background-color: rgba(255,255,255, 0.1);
      color: #ffffff;
      overflow:hidden;
      text-overflow:ellipsis;
      white-space:nowrap;
      width: 12.5%;
      font-size: 60rpx;
    }
  }

  @keyframes voice-wave {
    0% {
      transform: scale(1,1);
    }
    5% {
      transform: scale(1.05,1.05);
    }
    10% {
      transform: scale(1.1,1.1);
    }

    12% {
      transform: scale(1.2,1.2);
    }

    20% {
      transform: scale(1.1,1.1);
    }

    40% {
      transform: scale(1,1);
    }

    50% {
      transform: scale(1.05,1.05);
    }

    60% {
      transform: scale(1.2,1.2);
    }

    80% {
      transform: scale(1.15,1.15);
    }

    90% {
      transform: scale(1.05,1.05);
    }

    100% {
      transform: scale(1.0, 1.0);
    }
  }

  @-webkit-keyframes voice-wave {
    0% {
      transform: scale(1,1);
    }
    5% {
      transform: scale(1.05,1.05);
    }
    10% {
      transform: scale(1.1,1.1);
    }

    12% {
      transform: scale(1.2,1.2);
    }

    20% {
      transform: scale(1.1,1.1);
    }

    40% {
      transform: scale(1,1);
    }

    50% {
      transform: scale(1.05,1.05);
    }

    60% {
      transform: scale(1.2,1.2);
    }

    80% {
      transform: scale(1.15,1.15);
    }

    90% {
      transform: scale(1.05,1.05);
    }

    100% {
      transform: scale(1.0, 1.0);
    }
  }

</style>
<template>
  <view class="emoji-voice-wrap {{type}} {{reveal ? 'quick_show' : ''}}" animation="{{animationData}}">
    <scroll-view scroll-y="{{type=='emoji'}}" style=" height: {{height}};"  scroll-with-animation="true">
      <view class="emoji-list" wx:if="{{type == 'emoji'}}">
        <repeat for="{{emojiChar}}" key="key" index="index" item="item">
          <text class="text" bindtap="select({{item}})">{{item}}</text>
        </repeat>
      </view>
      <view class="speech-wrap" wx:if="{{type == 'voice'}}">
        <!--<image wx:if="{{isRequesting}}" class="voice-recording" mode="aspectFit" src="/common/img/recording.gif"></image>-->
        <view class="speech_text">{{speech_text}}</view>
        <view class="wave1 {{isRecording? 'recording':''}}"></view>
        <view class="wave2 {{isRecording? 'recording':''}}"></view>
        <button hover-class=""  class="voice-btn"
                hover-start-time="1"
                hover-stay-time="1"
                @touchstart="touchStart"
                @touchmove="touchMove"
                @touchend="touchEnd">
          <image class="voice-icon" mode="aspectFit" src="{{voice_icon}}"></image>
        </button>
      </view>
    </scroll-view>
  </view>
</template>
<script>
  import wepy from 'wepy'
  import md5 from 'md5'
  import baseMixin from '../mixins/base'
  import util from '@/utils/util.js'

  export default class Panel extends wepy.component {
    data = {
      recs: [],
      reveal: false,
      animationData: '',
      height: '200px',
      emojiChar: ['â˜º', 'ğŸ˜‹', 'ğŸ˜Œ', 'ğŸ˜', 'ğŸ˜', 'ğŸ˜œ', 'ğŸ˜', 'ğŸ˜', 'ğŸ˜”', 'ğŸ˜ª', 'ğŸ˜­', 'ğŸ˜', 'ğŸ˜‚', 'ğŸ˜ƒ', 'ğŸ˜…', 'ğŸ˜†', 'ğŸ‘¿', 'ğŸ˜’', 'ğŸ˜“', 'ğŸ˜”', 'ğŸ˜', 'ğŸ˜–', 'ğŸ˜˜', 'ğŸ˜š', 'ğŸ˜’', 'ğŸ˜¡', 'ğŸ˜¢', 'ğŸ˜£', 'ğŸ˜¤', 'ğŸ˜¢', 'ğŸ˜¨', 'ğŸ˜³', 'ğŸ˜µ', 'ğŸ˜·', 'ğŸ˜¸', 'ğŸ˜»', 'ğŸ˜¼', 'ğŸ˜½', 'ğŸ˜¾', 'ğŸ˜¿', 'ğŸ™Š', 'ğŸ™‹', 'ğŸ™', 'âœˆ', 'ğŸš‡', 'ğŸšƒ', 'ğŸšŒ', 'ğŸ„', 'ğŸ…', 'ğŸ†', 'ğŸ‡', 'ğŸˆ', 'ğŸ‰', 'ğŸ‘', 'ğŸ’', 'ğŸ“', 'ğŸ”', 'ğŸ¶', 'ğŸ·', 'ğŸ‘¦', 'ğŸ‘§', 'ğŸ‘±', 'ğŸ‘©', 'ğŸ‘°', 'ğŸ‘¨', 'ğŸ‘²', 'ğŸ‘³', 'ğŸ’ƒ', 'ğŸ’„', 'ğŸ’…', 'ğŸ’†', 'ğŸ’‡', 'ğŸŒ¹', 'ğŸ’‘', 'ğŸ’“', 'ğŸ’˜', 'ğŸš²'],
      voice_icon: '/common/img/voice@2x.png',
      vibrateTimer: '',
      recordCancel: false,
      isRecording: false,
      isRequesting: false,
      has_send: false,
      recordSeq: 0,
      btnText: '',
      recorderManager: null,
      speech_id: '',
      speech_seq: 0,
      speech_text: '',
      cancelText: ''
    }
    props = {
      type: String
    }

    mixins = [baseMixin]

    methods = {
      select (item) {
        let random = Math.random() * 1000000000000000
        this.$emit('add-emoji', item + '|' + random)
      },
      touchStart (e) {
        console.log('touch start')
        this.touchDot = e.touches[0]['pageY']
        this.recordCancel = false
        this.isRecording = true
        this.isRequesting = true
        this.speech_id = this.uniq()
        this.speech_seq = 0
        this.speech_text = ''
        this.longpress()
      },
      touchMove (e) {
        this.touchMoveDot = e.touches[0]['pageY']
        // console.log(this.touchMoveDot - this.touchDot)
        if (this.touchMoveDot - this.touchDot < -50) {
          // console.log('quxiao fasong')
          this.recordCancel = true
          // this.$invoke('../speach', 'cancel', {})
        } else {
          // hide cancel
          this.recordCancel = false
          // this.$invoke('../speach', 'hideCancel', {})
        }
      },
      touchEnd (e) {
        console.log('touch end')
        const self = this
        this.btnText = this.globalization['listening']
        // this.speech_seq = 0
        this.isRecording = false
        this.$invoke('../keyboard', 'modifyTip', this.btnText)
        setTimeout(() => { self.recorderManager.stop() }, 300)
      },
      shortTap (e) {
        console.log('short tap')
      },
      longTap (e) {
        this.longpress()
        /* recorderManager.onFrameRecorded((res) => {
         const { frameBuffer } = res
         console.log('frameBuffer.byteLength', frameBuffer.byteLength)
         }) */
        // this.$invoke('counter', 'minus', 45, 6)
      },
      confirm (e) {
        let value = this.trim(e.detail.value)
        if (!value) {
          return
        }
        this.sendValue = null // Math.random()
        this.setData({
          sendValue: ''
        })
        this.$apply()
        this.$emit('add-message', {
          type: 'customer',
          content: value
        })
      }
    }

    longpress () {
      const self = this
      // console.log('longTap2222')
      this.btnText = this.cancelText
      /* let promise = this.$invoke('speachtoast', 'show', {
       title: 'è‡ªå®šä¹‰æ ‡é¢˜',
       img: 'https://raw.githubusercontent.com/kiinlam/wetoast/master/images/star.png'
       }) */
      const options = {
        // duration: 3000,
        sampleRate: 16000,
        numberOfChannels: 2,
        encodeBitRate: 64000,
        frameSize: 5,
        format: 'mp3'
      }
      if (self.recorderManager) {
        self.recorderManager.start(options)
      }
      this.startVibrate()

      this.$invoke('../keyboard', 'modifyTip', this.btnText)

      /* this.$invoke('../speach', 'show', {
        // img: '../common/img/speaching.png',
        tip: ' ',
        title: 'è†å¬ä¸­,è¯·è¯´è¯...',
        notice: 'æ‰‹æŒ‡ä¸Šåˆ’,å–æ¶ˆå‘é€',
        duration: 1000 * 60
        // no_mask: true
      }) */
    }
    startVibrate () {
      // çŸ­æ—¶éœ‡åŠ¨
      wx.vibrateLong({
        success: function () {
          console.log('éœ‡åŠ¨æˆåŠŸ')
        },
        fail: function () {
          console.log('éœ‡åŠ¨å¤±è´¥')
        }
      })
      /* if (this.vibrateTimer) {
       clearTimeout(this.vibrateTimer)
       this.vibrateTimer = null
       }
       this.vibrateTimer = setTimeout(() => {
       wx.vibrateLong({
       success: function () {
       console.log('éœ‡åŠ¨æˆåŠŸ')
       },
       fail: function () {
       console.log('éœ‡åŠ¨å¤±è´¥')
       }
       })
       }, 200) */
    }
    initRecordManager () {
      const self = this
      const recorderManager = wx.getRecorderManager()
      this.recorderManager = recorderManager

      recorderManager.onStart(() => {
        console.log('recorder start')
      })
      recorderManager.onResume(() => {
        console.log('recorder resume')
      })
      recorderManager.onPause(() => {
        console.log('recorder pause')
      })
      recorderManager.onStop((res) => {
        console.log('stop end')
      })
      /*
      recorderManager.onStop((res) => {
        console.log('recorder stop', res)
        const { tempFilePath } = res

        // is
        if (this.recordCancel) {
          // this.$invoke('../speach', 'hide', {})
          self.isRequesting = false
          self.$apply()
          return
        }
        // ä¸Šä¼ è¯­éŸ³æ–‡ä»¶è‡³æœåŠ¡å™¨
        wepy.uploadFile({
          url: self.host + 'voice/recognize',
          filePath: tempFilePath,
          name: 'record',
          // header: {}, // è®¾ç½®è¯·æ±‚çš„ header
          formData: {
            'msg': 'voice'
          }, // HTTP è¯·æ±‚ä¸­å…¶ä»–é¢å¤–çš„ form data
          complete: function () {
            // complete
            console.log('complete')
            // self.$invoke('../speach', 'hide', {})
          }
        }).then(res => {
          // success
          // let result = JSON.parse(res.data)
          const json = JSON.parse(res.data)
          const voiceText = json.data.result || []
          // console.log(voiceText)
          // send a voice message
          console.log(voiceText)
          if (json.data.err_no) {
            self.$emit('add-message', {
              type: 'me',
              content: 'å¯¹ä¸èµ·ï¼Œæ²¡å¬æ¸…æ¥šæ‚¨è¯´ä»€ä¹ˆ~'
            })
          } else {
            console.log(11)
            let text =  voiceText[0].slice(0, voiceText[0].length - 1)
            self.speech_text = text
            self.$emit('add-message', {
              type: 'customer',
              content: text
            })
            self.$apply()
          }
        }, err => {
          console.log(err)
        }).then(() => {
          self.isRequesting = false
          self.$apply()
          // self.$invoke('../speach', 'hide', {})
        })
      })
      */
      recorderManager.onFrameRecorded((res) => {
        const { frameBuffer, isLastFrame } = res

        let str = new Uint8Array(frameBuffer).reduce((data, byte) => data + String.fromCharCode(byte), '')
        let base64 = util.btoa(str)
        // console.log( self.speech_seq * base64.length )
        let query = {
          'app_id': '1106827401',
          'format': '8',
          'rate': '16000',
          'bits': '16',
          'seq': self.speech_seq + '',
          'len': base64.length,
          'end': isLastFrame ? '1' : '0',
          'speech_id': self.speech_id,
          // 'speech_chunk': base64,
          'cont_res': '1',
          'time_stamp': parseInt(new Date().getTime() / 1000),
          'nonce_str': self.uniq()
        }
        console.log(query)
        query['speech_chunk'] = base64
        let sign = self.getSign(query)
        query['sign'] = sign
        self.request(query)
        self.speech_seq += frameBuffer.byteLength
        // console.log('frameBuffer.byteLength', frameBuffer.byteLength)
      })
      recorderManager.onError(() => {
        console.log('record error')
      })
    }

    request (query) {
      let self = this
      wepy.request({
        method: 'post',
        data: query,
        header: {
          'content-type': 'application/x-www-form-urlencoded'
        },
        url: 'https://api.ai.qq.com/fcgi-bin/aai/aai_wxasrs'
      }).then((res) => {
        console.log(res)
        if (res.statusCode == 200 && res.data.ret == 0) {
          let data = res.data.data
          if (data.speech_text) {
            self.speech_text = data.speech_text
            // self.has_send = true
            self.$apply()
          }
          if (data.is_final_res == 1) {
            self.$emit('add-message', {
              type: 'customer',
              content: self.speech_text
            })
          }else{}
        } else {
          /* console.log(11)
          self.$emit('add-message', {
            type: 'me',
            content: 'å¯¹ä¸èµ·ï¼Œæ²¡å¬æ¸…æ¥šæ‚¨è¯´ä»€ä¹ˆ~'
          }) */
        }
      }).then(() => {
        self.isRequesting = false
        this.$apply()
      })
    }

    uniq () {
      var uniq = (new Date()).getTime() + '-'
      for (var i = 1; i <= 18; i++) {
        var n = Math.floor(Math.random() * 16.0).toString(16)
        uniq += n
      }
      return uniq
    }

    getSign (queries) {
      // æŒ‰å­—å…¸æ’åº
      let params = Object.keys(queries).sort(function (a, b) {
        return a > b ? 1 : -1
      })

      let values = []
      for (let key of params) {
        if (queries[key]) {
          values.push(key + '=' + encodeURIComponent(queries[key]))
        }
      }
      // æœ«å°¾åŠ ä¸Šsecretkey
      let appKey = 'VmeAP8GpmSaErW4V'
      values.push('app_key=' + appKey)
      // console.log(values);

      let rawStr = values.join('&') // [account, cid, ip, PUBLIC_KEY, question, sessionId, PRIVATE_KEY].join('')
      // console.log(raw_str)
      let sign = md5(rawStr).toUpperCase()
      return sign
    }

    show () {
      console.log('show')
      this.speech_text = ''
      clearTimeout(this.__timeout)
      let animation = wx.createAnimation({
        duration: 50
      })
      animation.opacity(1).height(this.height).step()
      this.animationData = animation.export()
      this.reveal = true
      this.$apply()
      return new Promise((resolve, reject) => {
        this.__timeout = setTimeout(() => {
          resolve()
        }, 50)
      })
    }

    hide () {
      console.log('hide')
      this.reveal = false

      let animation = wx.createAnimation({
        duration: 50
      })
      animation.opacity(0).height(0).step()
      this.animationData = animation.export()

      this.$apply()
      return new Promise((resolve, reject) => {
        this.__timeout = setTimeout(() => {
          resolve()
        }, 50)
      })
    }

    onLoad () {
      let self = this
      this.globalization = this.getLanguage()
      this.cancelText = this.globalization['upCancel']
      this.voice_icon = this.getImg('/common/img/voice', 'png')
      this.initRecordManager()
      this.$apply()
      /*
      wepy.request('getRecommend').then((d) => {})
      */
    }
  }
</script>
